{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2\n",
    "\n",
    "Run three experiments and return scores for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import util\n",
    "import model\n",
    "import config\n",
    "from model_rnn import RNNAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_ensemble_model(rnn_train_data, rnn_test_datas, xgb_train_data, xgb_test_datas, xgb_cv_folds, config):\n",
    "    \"\"\"\n",
    "    Trains an ensemble model on the provided data, returns trained RNN and XGB models, CV score and test scores.\n",
    "    Used for stage 2, experiments 1 and 2.\n",
    "    \n",
    "    Steps:\n",
    "    (1) Trains a RNN autoencoder on @rnn_train_data, then uses generated embeddings as additional input to\n",
    "    the XGB (basically, appends the predictions to the @xgb_cv_data).\n",
    "    (2) Trains an ensemble XGB model using the provided folds @xgb_cv_folds. Reports the CV score.\n",
    "    (3) Fr testing, first generates RNN embeddings for each of @rnn_test_data. Appends them to @xgb_test_data\n",
    "    and reports the test scores of the ensemble model on each of test dataset.\n",
    "\n",
    "    Args:\n",
    "        rnn_train_data:   np.array; \n",
    "                          sequential data for training the RNN autoencoder (without labels)\n",
    "        rnn_test_datas:   list of np.array;\n",
    "                          list of sequential data for generating test predictions with RNN autoencoder\n",
    "        xgb_train_data:   tuple (np.array, np.array);\n",
    "                          data for training and validation of the XGBoost (ensemble) model\n",
    "        xgb_test_datas:   list of tuple (np.array, np.array);\n",
    "                          array of datasets used for testing\n",
    "        xgb_cv_folds:     list of tuple (np.array, np.array);\n",
    "                          cross-validation folds used for training and validation of the XGBoost model\n",
    "        config:           object;\n",
    "                          configuration object\n",
    "\n",
    "    Returns:\n",
    "        rnn_model:        RNNAutoencoder;\n",
    "                          trained recurrent model\n",
    "        ensemble_model:   xgboost.XGBClassifier;\n",
    "                          trained ensemble (XGBoost) model\n",
    "        cv_score:         list(3);\n",
    "                          array length 3 with the mean and CI for the CV AUC score on the provided folds\n",
    "        test_scores:      list of list(3);\n",
    "                          array of length which is equal to len(@xgb_test_data), with the means and CIs (based on\n",
    "                          100 runs with different random seeds) of AUC scores for every test dataset provided\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train RNN\n",
    "    rnn_model = LSTM_Autoencoder(config.RNN_OPTIMIZER, config.RNN_LOSS, config.RNN_LSTM_SIZE, config.RNN_DENSE_SIZE)\n",
    "    rnn_model.fit(rnn_train_data, epochs=config.RNN_EPOCHS_MAIN, batch_size=config.RNN_BATCH_SIZE)\n",
    "    \n",
    "    # Append RNN embeddings to XGBoost train data\n",
    "    rnn_train_embeddings = rnn_model.encode(rnn_train_data).numpy()\n",
    "    xgb_train_data = (\n",
    "        np.concatenate([xgb_train_data[0], rnn_train_embeddings.reshape(-1, 1)], axis=1),\n",
    "        xgb_train_data[1]\n",
    "    )\n",
    "    \n",
    "    # Append RNN embeddings to XGBoost test data\n",
    "    for i in range(len(xgb_test_datas)):\n",
    "        test_embedding = rnn_model.encode(rnn_test_datas[i]).numpy()\n",
    "        xgb_test_datas[i] = (\n",
    "            np.concatenate([xgb_test_datas[i][0], test_embedding.reshape(-1, 1)], axis=1),\n",
    "            xgb_test_datas[i][1]\n",
    "        )\n",
    "    \n",
    "    # Calculate ensemble XGBoost CV score\n",
    "    cv_score = model.calc_xgb_cv_auc(config.XGB_PARAMS, xgb_train_data[0], xgb_train_data[1], xgb_cv_folds)\n",
    "    \n",
    "    # Calculate ensemble XGBoost test scores\n",
    "    test_scores = []\n",
    "    for xgb_test_data in xgb_test_datas:\n",
    "        scores, ensemble_model = model.calc_xgb_auc_based_on_multiple_runs_and_return_model(\n",
    "            config.XGB_PARAMS, xgb_train_data[0], xgb_train_data[1], xgb_test_data[0], xgb_test_data[1])\n",
    "        test_scores.append(scores)\n",
    "    \n",
    "    return rnn_model, ensemble_model, cv_score, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_eval_ensemble_model(rnn_model, xgb_model_loc, rnn_tune_data, rnn_test_data, xgb_tune_data,\n",
    "                                 xgb_test_data, xgb_cv_folds, config):\n",
    "    \"\"\"\n",
    "    Fine-tunes given ensemble model on the provided data, returns CV score and test scores.\n",
    "    Used for stage 2, experiment 3.\n",
    "    \n",
    "    Steps:\n",
    "    (1) Fine-tunes a RNN autoencoder on @rnn_tune_data, then uses generated embeddings as additional input to\n",
    "    the XGB (basically, appends the predictions to the @xgb_tune_data).\n",
    "    (2) Fine-tunes an ensemble XGB model using the provided folds @xgb_cv_folds. Reports the CV score.\n",
    "    (3) For testing, first generates RNN embeddings for each of @rnn_test_data. Appends them to @xgb_test_data\n",
    "    and reports the test scores of the ensemble model on each of test dataset.\n",
    "\n",
    "    Args:\n",
    "        rnn_model:        RNNAutoencoder; \n",
    "                          pre-trained RNN model\n",
    "        xgb_model_loc:    str; \n",
    "                          location of the saved pre-trained XGBoost model\n",
    "        rnn_tune_data:    np.array; \n",
    "                          sequential data for fine-tuning the RNN autoencoder (without labels) (COVID)\n",
    "        rnn_test_data:    np.array;\n",
    "                          sequential data for generating test predictions with RNN autoencoder (non-COVID test)\n",
    "        xgb_tune_data:    tuple (np.array, np.array);\n",
    "                          data for fine-tuning of the XGBoost (ensemble) model                 (COVID)\n",
    "        xgb_test_data:    list of tuple (np.array, np.array);\n",
    "                          data for testing of the XGBoost (ensemble) model                     (non-COVID test)\n",
    "        xgb_tune_folds:   list of tuple (np.array, np.array);\n",
    "                          folds used for fine-tuning and evaluation of the ensemble model      (COVID folds)\n",
    "        config:           object;\n",
    "                          configuration object\n",
    "\n",
    "    Returns:\n",
    "        cv_score:         list(3);\n",
    "                          array length 3 with the mean and CI for the CV AUC score of the fine-tuned model\n",
    "                          on COVID dataset using the provided @xgb_test_folds folds\n",
    "        test_score:       list(3);\n",
    "                          array of length which is equal to len(@xgb_test_data), with the means and CIs of AUC\n",
    "                          scores of the fine-tuned model on the non-COVID test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fine-tune RNN\n",
    "    rnn_model.fit(rnn_tune_data, epochs=config.RNN_EPOCHS_MAIN, batch_size=config.RNN_BATCH_SIZE)\n",
    "    \n",
    "    # Append generated RNN embeddings to XGB tune data\n",
    "    rnn_tune_embeddings = rnn_model.encode(rnn_tune_data).numpy()\n",
    "    xgb_tune_data = (\n",
    "        np.concatenate([xgb_tune_data[0], rnn_tune_embeddings.reshape(-1, 1)], axis=1),\n",
    "        xgb_tune_data[1]\n",
    "    )\n",
    "    \n",
    "    # Append generated RNN embeddings to XGB test data\n",
    "    rnn_test_embeddings = rnn_model.encode(rnn_test_data).numpy()\n",
    "    xgb_test_data = (\n",
    "        np.concatenate([xgb_test_data[0], rnn_test_embeddings.reshape(-1, 1)], axis=1),\n",
    "        xgb_test_data[1]\n",
    "    )\n",
    "\n",
    "    # Fine-tune and evaluate XGBoost (ensemble) model\n",
    "    scores_covid = []\n",
    "    for fold in xgb_tune_folds:\n",
    "        covid_train = (xgb_tune_data[0][fold[0]], xgb_tune_data[1][fold[0]])\n",
    "        covid_test = (xgb_tune_data[0][fold[1]], xgb_tune_data[1][fold[1]])\n",
    "        scores_covid.append(model.fine_tune_and_calc_auc_based_on_multiple_runs(xgb_model_loc, config.XGB_PARAMS,\n",
    "                                                      covid_train[0], covid_train[1],\n",
    "                                                      covid_test[0], covid_test[1]))\n",
    "    score_covid = model.calc_mean_and_confidence_interval(scores_covid)\n",
    "        \n",
    "    # Fine-tune on all COVID and evaluate on non-COVID\n",
    "    score_noncovid = model.fine_tune_and_calc_auc_based_on_multiple_runs(xgb_model_loc, config.XGB_PARAMS,\n",
    "                                                                        xgb_tune_data[0] xgb_tune_data[1],\n",
    "                                                                        xgb_test_data[0], xgb_test_data[1])\n",
    "    \n",
    "    return score_covid, score_noncovid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for RNN\n",
    "noncovid_rnn_train_data = util.load_data_rnn(config.NONCOVID_RNN_TRAIN_DATA_LOC)\n",
    "noncovid_rnn_test_data = util.load_data_rnn(config.NONCOVID_RNN_TEST_DATA_LOC)\n",
    "covid_rnn_data = util.load_data_rnn(config.COVID_RNN_DATA_LOC)\n",
    "\n",
    "# Load data for XGBoost\n",
    "_, x, y, _ = util.load_data(config.NONCOVID_XGB_TRAIN_DATA_LOC)\n",
    "noncovid_xgb_train_data = (x, y)\n",
    "_, x, y, _ = util.load_data(config.NONCOVID_XGB_TEST_DATA_LOC)\n",
    "noncovid_xgb_test_data = (x, y)\n",
    "_, x, y, _ = util.load_data(config.COVID_XGB_DATA_LOC)\n",
    "covid_xgb_data = (x, y)\n",
    "\n",
    "# Load CV folds\n",
    "noncovid_xgb_cv_folds = util.load_folds(noncovid_xgb_train_data, config.NONCOVID_CV_SPLITS_LOC)\n",
    "covid_xgb_cv_folds = util.load_folds(covid_xgb_train_data, config.COVID_CV_SPLITS_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "\n",
    "rnn_model, ensemble_model, score_covid_experiment1, score_noncovid_experiment1 = train_eval_ensemble_model(\n",
    "    noncovid_rnn_train_data,\n",
    "    [noncovid_rnn_test_data, covid_rnn_data],\n",
    "    noncovid_xgb_train_data,\n",
    "    [noncovid_xgb_test_data, covid_xgb_data],\n",
    "    noncovid_xgb_cv_folds,\n",
    "    config\n",
    ")\n",
    "ensemble_model.save_model('ensemble_model_dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "\n",
    "_, _, score_covid_experiment2, score_noncovid_experiment2 = train_eval_ensemble_model(\n",
    "    covid_rnn_data,\n",
    "    [noncovid_rnn_test_data],\n",
    "    covid_xgb_data,\n",
    "    [noncovid_xgb_test_data],\n",
    "    covid_xgb_cv_folds,\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "\n",
    "_, _, score_covid_experiment3, score_noncovid_experiment3 = finetune_eval_ensemble_model(\n",
    "    rnn_model,\n",
    "    'ensemble_model_dump',\n",
    "    covid_rnn_data,\n",
    "    noncovid_rnn_test_data,\n",
    "    covid_xgb_data,\n",
    "    noncovid_xgb_test_data,\n",
    "    covid_xgb_cv_folds,\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_covid_experiment1, score_noncovid_experiment1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_covid_experiment2, score_noncovid_experiment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_covid_experiment3, score_noncovid_experiment3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
